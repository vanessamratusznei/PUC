{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7a6b36-3ceb-4d9f-b3e2-1cfb0222110d",
   "metadata": {},
   "source": [
    "# Conexão com o Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5f19ac-43ff-4b52-9346-a03db5a03402",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12182/23586936.py:2: FutureWarning: pyarrow.hdfs.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  hdfs.HadoopFileSystem(\"hdfs://namenode:9000\")\n"
     ]
    }
   ],
   "source": [
    "from pyarrow import fs, hdfs\n",
    "hdfs.HadoopFileSystem(\"hdfs://namenode:9000\")\n",
    "conexao = fs.HadoopFileSystem(host=\"namenode\", port=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd068a-2e7d-4712-a806-a1df12f2eaee",
   "metadata": {},
   "source": [
    "## Preparar Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66be18fe-26a2-4191-bf3e-d69eb173537b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#navegar pelas pastas\n",
    "conexao.get_file_info(fs.FileSelector('/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d7203-ab93-42a3-9c11-8b804ad58678",
   "metadata": {},
   "source": [
    "### Diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83195d7e-7690-406f-b723-e5ce25b32361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar pastas\n",
    "conexao.create_dir('/somativa2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddabdb1-7841-4d28-9a04-55d318bbc533",
   "metadata": {},
   "source": [
    "### Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c3695d-a591-4487-8c66-90e8c0671209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar Arquivos\n",
    "caminho_arquivo_origem = 'sentiment140.csv'\n",
    "caminho_arquivo_destino = '/somativa2/sentiment140.csv'\n",
    "\n",
    "#Escrever Arquivo\n",
    "with conexao.open_output_stream(caminho_arquivo_destino) as stream:\n",
    "    stream.write(open(caminho_arquivo_origem, 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236e455-29b1-4249-a310-42ea0dd9340b",
   "metadata": {},
   "source": [
    "# Importando PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7d8c4f-dd18-461c-a640-132733d4cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import to_timestamp, expr\n",
    "from pyspark.sql.functions import col, lower, explode, split, regexp_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7243b-9777-4934-a03b-89bd8f01fc8a",
   "metadata": {},
   "source": [
    "## Sessão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fd6196-9d01-4d32-8c8e-2def5079e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar sessao\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace665c-c1bb-42fd-9c64-7f545e520274",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "049937ff-b619-4055-91a6-3acf7416c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler arquivo e criar dataframe\n",
    "df = spark.read.csv('hdfs://namenode:9000/somativa2/sentiment140.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f315d4-9520-4d0f-949f-71c6f804e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------------+-------------------+--------------------+-------------------------+\n",
      "|           target|                 ids|        date|               flag|                user|text;;;;;;;;;;;;;;;;;;;;;|\n",
      "+-----------------+--------------------+------------+-------------------+--------------------+-------------------------+\n",
      "|\"0,\"\"1467810369\"\"|\"\"Mon Apr 06 22:1...|\"\"NO_QUERY\"\"|\"\"_TheSpecialOne_\"\"|\"\"@switchfoot htt...|      that's a bummer....|\n",
      "|\"0,\"\"1467810672\"\"|\"\"Mon Apr 06 22:1...|\"\"NO_QUERY\"\"|  \"\"scotthamilton\"\"|\"\"is upset that h...|                     NULL|\n",
      "|\"0,\"\"1467810917\"\"|\"\"Mon Apr 06 22:1...|\"\"NO_QUERY\"\"|       \"\"mattycus\"\"|\"\"@Kenichan I div...|                     NULL|\n",
      "|\"0,\"\"1467811184\"\"|\"\"Mon Apr 06 22:1...|\"\"NO_QUERY\"\"|        \"\"ElleCTF\"\"|\"\"my whole body f...|                     NULL|\n",
      "|\"0,\"\"1467811193\"\"|\"\"Mon Apr 06 22:1...|\"\"NO_QUERY\"\"|         \"\"Karoli\"\"|\"\"@nationwideclas...|      it's not behavin...|\n",
      "|\"0,\"\"1467811372\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|       \"\"joy_wolf\"\"|\"\"@Kwesidei not t...|                     NULL|\n",
      "|\"0,\"\"1467811592\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|        \"\"mybirch\"\"|\"\"Need a hug \"\"\";...|                     NULL|\n",
      "|\"0,\"\"1467811594\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|           \"\"coZZ\"\"|\"\"@LOLTrish hey  ...|         only a bit  LOL |\n",
      "|\"0,\"\"1467811795\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|\"\"2Hood4Hollywood\"\"|\"\"@Tatiana_K nope...|                     NULL|\n",
      "|\"0,\"\"1467812025\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|        \"\"mimismo\"\"|\"\"@twittera que m...|                     NULL|\n",
      "|\"0,\"\"1467812416\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"| \"\"erinx3leannexo\"\"|\"\"spring break in...|                     NULL|\n",
      "|\"0,\"\"1467812579\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|   \"\"pardonlauren\"\"|\"\"I just re-pierc...|                     NULL|\n",
      "|\"0,\"\"1467812723\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|           \"\"TLeC\"\"|\"\"@caregiving I c...|                     NULL|\n",
      "|\"0,\"\"1467812771\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|\"\"robrobbierobert\"\"|\"\"@octolinz16 It ...|      idk why I did ei...|\n",
      "|\"0,\"\"1467812784\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|    \"\"bayofwolves\"\"|\"\"@smarrison i wo...|      but i didn't hav...|\n",
      "|\"0,\"\"1467812799\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|     \"\"HairByJess\"\"|\"\"@iamjazzyfizzle...|                     NULL|\n",
      "|\"0,\"\"1467812964\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"| \"\"lovesongwriter\"\"|\"\"Hollis' death s...|                     NULL|\n",
      "|\"0,\"\"1467813137\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|       \"\"armotley\"\"|\"\"about to file t...|                     NULL|\n",
      "|\"0,\"\"1467813579\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|     \"\"starkissed\"\"|\"\"@LettyA ahh ive...|                     NULL|\n",
      "|\"0,\"\"1467813782\"\"|\"\"Mon Apr 06 22:2...|\"\"NO_QUERY\"\"|      \"\"gi_gi_bee\"\"|\"\"@FakerPattyPatt...|                     NULL|\n",
      "+-----------------+--------------------+------------+-------------------+--------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d55ba7-9bfb-4993-9258-30bfae19a595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[target: string, ids: string, date: string, flag: string, user: string, text;;;;;;;;;;;;;;;;;;;;;: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar colunas e respectivos tipos\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724425c-6cf5-445b-91c4-f9daf2e6b072",
   "metadata": {},
   "source": [
    "### Organizar DataFrame\n",
    "\n",
    "Para facilitar a análise dos dados, vamos organizar as informações do DataFrame, removendo inicialmente as colunas que não são relevantes para a análise, como a coluna 'target' e 'flag'.\n",
    "\n",
    "Contrariando o planejamento inicial, a coluna 'date' se revelou importante, pois é esperado que contenha informações de data e tempo. No entanto, parece que durante a coleta dos dados, os valores que deveriam estar em 'date' foram erroneamente armazenados na coluna 'ids'. Para corrigir esse equívoco, vamos renomear a coluna 'ids' para 'date'.\n",
    "\n",
    "Uma revisão preliminar das colunas 'user' e 'text;;;;;;;;;;;;;;;;;;;;;' sugere que é possível combinar seus conteúdos em uma única coluna. Portanto, vamos fundir essas duas colunas em uma nova chamada 'text'. Com isso, as colunas originais 'user' e 'text;;;;;;;;;;;;;;;;;;;;;' podem ser descartadas, pois todas as informações necessárias estarão contidas na nova coluna 'text'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13db6f31-7a1d-4699-8ead-22a16b152a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Excluir as colunas 'target' e 'date'\n",
    "df = df.drop('target', 'flag', 'date')\n",
    "\n",
    "# 2 - Renomear a coluna 'ids' para 'date'\n",
    "df = df.withColumnRenamed('ids', 'date')\n",
    "\n",
    "# 3 - Juntar as colunas 'user' e 'text;;;;;;;;;;;;;;;;;;;;;' usando concat_ws e um espaço como separador\n",
    "df = df.withColumn('text', F.concat_ws(' ', F.col('user'), F.col('text;;;;;;;;;;;;;;;;;;;;;')))\n",
    "\n",
    "# 4 - Depois de criada a coluna 'text', excluir as colunas 'user' e 'text;;;;;;;;;;;;;;;;;;;;;'\n",
    "df = df.drop('user', 'text;;;;;;;;;;;;;;;;;;;;;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60206153-db15-40c5-802a-bcd33012bf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|date                            |text                                                                                                                                          |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|\"\"Mon Apr 06 22:19:45 PDT 2009\"\"|\"\"@switchfoot http://twitpic.com/2y1zl - Awww  that's a bummer.  You shoulda got David Carr of Third Day to do it. \";\"D\"\"\";;;;;;;;;;;;;;;;;;;;|\n",
      "|\"\"Mon Apr 06 22:19:49 PDT 2009\"\"|\"\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"\"\";;;;;;;;;;;;;;;;;;;;;     |\n",
      "|\"\"Mon Apr 06 22:19:53 PDT 2009\"\"|\"\"@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\"\"\";;;;;;;;;;;;;;;;;;;;;                           |\n",
      "|\"\"Mon Apr 06 22:19:57 PDT 2009\"\"|\"\"my whole body feels itchy and like its on fire \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                     |\n",
      "|\"\"Mon Apr 06 22:19:57 PDT 2009\"\"|\"\"@nationwideclass no  it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"\"\";;;;;;;;;;;;;;;;;;;;;     |\n",
      "|\"\"Mon Apr 06 22:20:00 PDT 2009\"\"|\"\"@Kwesidei not the whole crew \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                       |\n",
      "|\"\"Mon Apr 06 22:20:03 PDT 2009\"\"|\"\"Need a hug \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                                         |\n",
      "|\"\"Mon Apr 06 22:20:03 PDT 2009\"\"|\"\"@LOLTrish hey  long time no see! Yes.. Rains a bit  only a bit  LOL                                                                         |\n",
      "|\"\"Mon Apr 06 22:20:05 PDT 2009\"\"|\"\"@Tatiana_K nope they didn't have it \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                |\n",
      "|\"\"Mon Apr 06 22:20:09 PDT 2009\"\"|\"\"@twittera que me muera ? \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                           |\n",
      "|\"\"Mon Apr 06 22:20:16 PDT 2009\"\"|\"\"spring break in plain city... it's snowing \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                         |\n",
      "|\"\"Mon Apr 06 22:20:17 PDT 2009\"\"|\"\"I just re-pierced my ears \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                          |\n",
      "|\"\"Mon Apr 06 22:20:19 PDT 2009\"\"|\"\"@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .\"\"\";;;;;;;;;;;;;;;;;;;;;                      |\n",
      "|\"\"Mon Apr 06 22:20:19 PDT 2009\"\"|\"\"@octolinz16 It it counts  idk why I did either. you never talk to me anymore \"\"\";;;;;;;;;;;;;;;;;;;;;                                       |\n",
      "|\"\"Mon Apr 06 22:20:20 PDT 2009\"\"|\"\"@smarrison i would've been the first  but i didn't have a gun.    not really though                                                         |\n",
      "|\"\"Mon Apr 06 22:20:20 PDT 2009\"\"|\"\"@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!\"\"\";;;;;;;;;;;;;;;;;;;;;             |\n",
      "|\"\"Mon Apr 06 22:20:22 PDT 2009\"\"|\"\"Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?\"\"\";;;;;;;;;;;;;;;;;;;;;                       |\n",
      "|\"\"Mon Apr 06 22:20:25 PDT 2009\"\"|\"\"about to file taxes \"\"\";;;;;;;;;;;;;;;;;;;;;                                                                                                |\n",
      "|\"\"Mon Apr 06 22:20:31 PDT 2009\"\"|\"\"@LettyA ahh ive always wanted to see rent  love the soundtrack!!\"\"\";;;;;;;;;;;;;;;;;;;;;                                                    |\n",
      "|\"\"Mon Apr 06 22:20:34 PDT 2009\"\"|\"\"@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks? \"\"\";;;;;;;;;;;;;;;;;;;;;                                     |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar o DataFrame resultante para verificar as mudanças\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a349ad-ec7b-4d9e-aa3a-8f0a01ccd8ff",
   "metadata": {},
   "source": [
    "Observa-se que a visualização dos valores das colunas ainda pode ser melhorada, visto que cada valor está precedido e seguido por dois caracteres de aspas (\"\"). Esses caracteres não adicionam informações relevantes e, portanto, podem ser removidos das strings. Isso tornará os valores mais 'limpos' e claros, facilitando a análise e interpretação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395a366e-44f0-4232-8718-c8c5463d6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|date                        |text                                                                                                                                      |\n",
      "+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Mon Apr 06 22:19:45 PDT 2009|@switchfoot http://twitpic.com/2y1zl - Awww  that's a bummer.  You shoulda got David Carr of Third Day to do it. \";\"D\";;;;;;;;;;;;;;;;;;;;|\n",
      "|Mon Apr 06 22:19:49 PDT 2009|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\";;;;;;;;;;;;;;;;;;;;;     |\n",
      "|Mon Apr 06 22:19:53 PDT 2009|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\";;;;;;;;;;;;;;;;;;;;;                           |\n",
      "|Mon Apr 06 22:19:57 PDT 2009|my whole body feels itchy and like its on fire \";;;;;;;;;;;;;;;;;;;;;                                                                     |\n",
      "|Mon Apr 06 22:19:57 PDT 2009|@nationwideclass no  it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \";;;;;;;;;;;;;;;;;;;;;     |\n",
      "|Mon Apr 06 22:20:00 PDT 2009|@Kwesidei not the whole crew \";;;;;;;;;;;;;;;;;;;;;                                                                                       |\n",
      "|Mon Apr 06 22:20:03 PDT 2009|Need a hug \";;;;;;;;;;;;;;;;;;;;;                                                                                                         |\n",
      "|Mon Apr 06 22:20:03 PDT 2009|@LOLTrish hey  long time no see! Yes.. Rains a bit  only a bit  LOL                                                                       |\n",
      "|Mon Apr 06 22:20:05 PDT 2009|@Tatiana_K nope they didn't have it \";;;;;;;;;;;;;;;;;;;;;                                                                                |\n",
      "|Mon Apr 06 22:20:09 PDT 2009|@twittera que me muera ? \";;;;;;;;;;;;;;;;;;;;;                                                                                           |\n",
      "|Mon Apr 06 22:20:16 PDT 2009|spring break in plain city... it's snowing \";;;;;;;;;;;;;;;;;;;;;                                                                         |\n",
      "|Mon Apr 06 22:20:17 PDT 2009|I just re-pierced my ears \";;;;;;;;;;;;;;;;;;;;;                                                                                          |\n",
      "|Mon Apr 06 22:20:19 PDT 2009|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .\";;;;;;;;;;;;;;;;;;;;;                      |\n",
      "|Mon Apr 06 22:20:19 PDT 2009|@octolinz16 It it counts  idk why I did either. you never talk to me anymore \";;;;;;;;;;;;;;;;;;;;;                                       |\n",
      "|Mon Apr 06 22:20:20 PDT 2009|@smarrison i would've been the first  but i didn't have a gun.    not really though                                                       |\n",
      "|Mon Apr 06 22:20:20 PDT 2009|@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!\";;;;;;;;;;;;;;;;;;;;;             |\n",
      "|Mon Apr 06 22:20:22 PDT 2009|Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?\";;;;;;;;;;;;;;;;;;;;;                       |\n",
      "|Mon Apr 06 22:20:25 PDT 2009|about to file taxes \";;;;;;;;;;;;;;;;;;;;;                                                                                                |\n",
      "|Mon Apr 06 22:20:31 PDT 2009|@LettyA ahh ive always wanted to see rent  love the soundtrack!!\";;;;;;;;;;;;;;;;;;;;;                                                    |\n",
      "|Mon Apr 06 22:20:34 PDT 2009|@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks? \";;;;;;;;;;;;;;;;;;;;;                                     |\n",
      "+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remover aspas extras de todas as colunas\n",
    "for col_name in df.columns:\n",
    "    df = df.withColumn(col_name, F.regexp_replace(F.col(col_name), '^\"\"|\"\"$', ''))\n",
    "\n",
    "# Para garantir que não há aspas no meio dos textos também (caso seja necessário)\n",
    "for col_name in df.columns:\n",
    "    df = df.withColumn(col_name, F.regexp_replace(F.col(col_name), '\"\"', ''))\n",
    "\n",
    "# Mostrar algumas linhas para confirmar as alterações\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6188a58-a5df-44c6-aa61-b2fbd0fbb12a",
   "metadata": {},
   "source": [
    "Para concluir, converteremos a coluna 'date' para o formato de timestamp. Isso nos permitirá realizar filtros precisos por data e hora nas análises subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c6f1e0-b9e5-4458-a509-8c063a76a5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|               date|                text|\n",
      "+-------------------+--------------------+\n",
      "|2009-04-06 22:19:45|@switchfoot http:...|\n",
      "|2009-04-06 22:19:49|is upset that he ...|\n",
      "|2009-04-06 22:19:53|@Kenichan I dived...|\n",
      "|2009-04-06 22:19:57|my whole body fee...|\n",
      "|2009-04-06 22:19:57|@nationwideclass ...|\n",
      "|2009-04-06 22:20:00|@Kwesidei not the...|\n",
      "|2009-04-06 22:20:03|Need a hug \";;;;;...|\n",
      "|2009-04-06 22:20:03|@LOLTrish hey  lo...|\n",
      "|2009-04-06 22:20:05|@Tatiana_K nope t...|\n",
      "|2009-04-06 22:20:09|@twittera que me ...|\n",
      "|2009-04-06 22:20:16|spring break in p...|\n",
      "|2009-04-06 22:20:17|I just re-pierced...|\n",
      "|2009-04-06 22:20:19|@caregiving I cou...|\n",
      "|2009-04-06 22:20:19|@octolinz16 It it...|\n",
      "|2009-04-06 22:20:20|@smarrison i woul...|\n",
      "|2009-04-06 22:20:20|@iamjazzyfizzle I...|\n",
      "|2009-04-06 22:20:22|Hollis' death sce...|\n",
      "|2009-04-06 22:20:25|about to file tax...|\n",
      "|2009-04-06 22:20:31|@LettyA ahh ive a...|\n",
      "|2009-04-06 22:20:34|@FakerPattyPattz ...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alterar o tipo da coluna existente de string para timestamp\n",
    "df = df.withColumn(\"date\", to_timestamp(\"date\", \"EEE MMM dd HH:mm:ss zzz yyyy\"))\n",
    "\n",
    "# Ajustar o fuso horário manualmente (subtrair 7 horas para PDT)\n",
    "df = df.withColumn(\"date\", expr(\"date - interval 7 hours\"))\n",
    "\n",
    "# Mostrar o resultado\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3359f-c3eb-4530-afb0-d466ef165ed7",
   "metadata": {},
   "source": [
    "## Análises\n",
    "\n",
    "- Mostrar as **palavras mais frequentes** nos tweets (similar ao código da tokenização)\n",
    "- Mostrar os **usuários mais mencionados** (isto é, todas as palavras iniciadas com um \"@\")\n",
    "- Mostrar os **hashtags mais frequentes** (isto é, todas as palvras iniciadas com um \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43c271-b10d-4912-acdb-4d16e36a250a",
   "metadata": {},
   "source": [
    "### Palavras Mais Frequentes \n",
    "Para analisar as palavras mais frequentes nos tweets, iremos considerar a coluna 'text':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a78f1f44-d388-4b66-b98b-e3fc9b5e736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover caracteres especiais antes de tokenizar\n",
    "# Limpar o texto mantendo '@' e '#' enquanto remove outros caracteres especiais como ';'\n",
    "cleaned_df = df.withColumn(\"clean_text\", regexp_replace(col(\"text\"), \"[^\\w\\s@#]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9936b522-eb97-41ba-ba72-16708f93addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar o texto e contar as palavras\n",
    "df_word = cleaned_df.withColumn(\"word\", explode(split(lower(col(\"clean_text\")), \"\\\\W+\"))) \\\n",
    "                   .groupBy(\"word\") \\\n",
    "                   .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c293b4ad-2c8b-4ca7-9fe6-cfdca79a0c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|word|  count|\n",
      "+----+-------+\n",
      "|    |1015209|\n",
      "|   i|  63424|\n",
      "|  to|  46496|\n",
      "| the|  36165|\n",
      "|  my|  26033|\n",
      "|   a|  26012|\n",
      "| and|  21408|\n",
      "|  is|  18954|\n",
      "|  in|  16622|\n",
      "|  it|  16289|\n",
      "| for|  14054|\n",
      "|  im|  13928|\n",
      "|  of|  13492|\n",
      "| you|  12466|\n",
      "|  me|  12247|\n",
      "|  on|  12166|\n",
      "|have|  11719|\n",
      "|  so|  11620|\n",
      "| but|  10823|\n",
      "| not|  10300|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenar o DataFrame pela coluna 'count' em ordem decrescente\n",
    "df_word = df_word.orderBy(F.desc(\"count\"))\n",
    "\n",
    "# Mostrar palavras com maior frequencia\n",
    "df_word.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724c826-5e65-445c-900a-5fe6e902046b",
   "metadata": {},
   "source": [
    "### Usuários Mais Mencionados\n",
    "Para analisar os usuários mais mencionados, também iremos considerar a coluna 'text', filtrando as palavras que iniciam com o caractere '@':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bd48e10-f972-4726-8f78-46e2edee095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar e contar menções de usuários\n",
    "# filtrar as palavras que começam com o caractere '@'\n",
    "df_mention = cleaned_df.withColumn(\"mention\", explode(split(col(\"clean_text\"), \"\\s+\"))) \\\n",
    "                .filter(col(\"mention\").startswith(\"@\")) \\\n",
    "                .groupBy(\"mention\") \\\n",
    "                .count() \\\n",
    "                .orderBy(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc2b5321-645c-411e-8ac6-2c19c8d6cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|         mention|count|\n",
      "+----------------+-----+\n",
      "|               @|  857|\n",
      "|       @tommcfly|  193|\n",
      "|     @mileycyrus|  188|\n",
      "|       @ddlovato|  122|\n",
      "|    @DavidArchie|  110|\n",
      "|     @stephenfry|   80|\n",
      "|      @petewentz|   62|\n",
      "| @DonnieWahlberg|   59|\n",
      "|@JonathanRKnight|   56|\n",
      "|    @nick_carter|   54|\n",
      "|   @joeymcintyre|   53|\n",
      "|         @aplusk|   50|\n",
      "|   @jordanknight|   50|\n",
      "|    @dougiemcfly|   46|\n",
      "|    @heidimontag|   43|\n",
      "|    @gfalcone601|   41|\n",
      "|  @amazingphoebe|   38|\n",
      "|     @JoelMadden|   37|\n",
      "|      @dannywood|   37|\n",
      "|   @shaundiviney|   36|\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar os usuários mais mencionados\n",
    "df_mention.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b55127-9e31-49cd-8f2f-2cebf5f2c8d9",
   "metadata": {},
   "source": [
    "### Hashtags Mais Frequentes\n",
    "\n",
    "Para analisar as hashtags mais frequentes, também iremos considerar a coluna 'text', filtrando as palavras que iniciam com o caractere '#':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36025402-ef19-43aa-be31-08abfa137ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar e contar menções de usuários\n",
    "# filtrar as palavras que começam com o caractere '#'\n",
    "df_hashtags = cleaned_df.withColumn(\"hashtags\", explode(split(col(\"clean_text\"), \"\\s+\"))) \\\n",
    "                .filter(col(\"hashtags\").startswith(\"#\")) \\\n",
    "                .groupBy(\"hashtags\") \\\n",
    "                .count() \\\n",
    "                .orderBy(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "653a197a-9fee-4151-b1db-f98c340f9058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      hashtags|count|\n",
      "+--------------+-----+\n",
      "|      #asot400|  110|\n",
      "|           #fb|  106|\n",
      "|           #f1|   37|\n",
      "|             #|   34|\n",
      "|         #fail|   33|\n",
      "|          #tag|   24|\n",
      "|      #ASOT400|   24|\n",
      "|            #1|   23|\n",
      "|           #F1|   20|\n",
      "|#3turnoffwords|   20|\n",
      "|   #fixreplies|   19|\n",
      "|            #2|   16|\n",
      "|   #shortstack|   15|\n",
      "|      #awaresg|   15|\n",
      "|     #pawpawty|   14|\n",
      "|    #hoppusday|   13|\n",
      "|     #swineflu|   13|\n",
      "| #followfriday|   12|\n",
      "|      #Tweetie|   12|\n",
      "|        #mcfly|   11|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar os hashtags mais frequentes\n",
    "df_hashtags.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57072039-75a1-46c8-9d02-4e23872102f1",
   "metadata": {},
   "source": [
    "### 10 Palavras Mais Frequentes por Dia da Semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c60769-c744-47a9-876d-216d61ceec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar uma coluna 'day_of_week' ao DataFrame que contém o nome do dia da semana\n",
    "df = df.withColumn(\"day_of_week\", F.date_format(F.col(\"date\"), \"EEEE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c1cfa68-9951-4c42-b763-10ff3244c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------+\n",
      "|               date|                text|day_of_week|\n",
      "+-------------------+--------------------+-----------+\n",
      "|2009-04-06 22:19:45|@switchfoot http:...|     Monday|\n",
      "|2009-04-06 22:19:49|is upset that he ...|     Monday|\n",
      "|2009-04-06 22:19:53|@Kenichan I dived...|     Monday|\n",
      "|2009-04-06 22:19:57|my whole body fee...|     Monday|\n",
      "|2009-04-06 22:19:57|@nationwideclass ...|     Monday|\n",
      "|2009-04-06 22:20:00|@Kwesidei not the...|     Monday|\n",
      "|2009-04-06 22:20:03|Need a hug \";;;;;...|     Monday|\n",
      "|2009-04-06 22:20:03|@LOLTrish hey  lo...|     Monday|\n",
      "|2009-04-06 22:20:05|@Tatiana_K nope t...|     Monday|\n",
      "|2009-04-06 22:20:09|@twittera que me ...|     Monday|\n",
      "|2009-04-06 22:20:16|spring break in p...|     Monday|\n",
      "|2009-04-06 22:20:17|I just re-pierced...|     Monday|\n",
      "|2009-04-06 22:20:19|@caregiving I cou...|     Monday|\n",
      "|2009-04-06 22:20:19|@octolinz16 It it...|     Monday|\n",
      "|2009-04-06 22:20:20|@smarrison i woul...|     Monday|\n",
      "|2009-04-06 22:20:20|@iamjazzyfizzle I...|     Monday|\n",
      "|2009-04-06 22:20:22|Hollis' death sce...|     Monday|\n",
      "|2009-04-06 22:20:25|about to file tax...|     Monday|\n",
      "|2009-04-06 22:20:31|@LettyA ahh ive a...|     Monday|\n",
      "|2009-04-06 22:20:34|@FakerPattyPattz ...|     Monday|\n",
      "+-------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edda5d5-012f-4d84-9bfa-d0e42e64f94b",
   "metadata": {},
   "source": [
    "#### Definir Funcao\n",
    "Vamos definir uma funcao que selecione as palavras mais frequentes considerando um dia da semana especifico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9137d040-7701-4138-bb28-b1337df069fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_by_day(df, day_of_week):\n",
    "    # Filtrar para apenas as entradas onde 'day_of_week' é especificado pelo parâmetro\n",
    "    day_df = df.filter(col(\"day_of_week\") == day_of_week)\n",
    "\n",
    "    # Remover caracteres especiais antes de tokenizar\n",
    "    # Isso garante que caracteres como ponto e vírgula e aspas sejam removidos\n",
    "    cleaned_df = day_df.withColumn(\"clean_text\", regexp_replace(col(\"text\"), r\"[^\\w\\s]\", \"\"))\n",
    "\n",
    "    # Tokenizar o texto limpo, converter para minúsculas e expandir em uma nova linha cada palavra\n",
    "    words_df = cleaned_df.withColumn(\"word\", explode(split(lower(col(\"clean_text\")), \"\\\\W+\")))\n",
    "\n",
    "    # Agrupar por 'word', contar e ordenar por frequência\n",
    "    word_counts = (words_df.groupBy(\"word\")\n",
    "                           .count()\n",
    "                           .orderBy(col(\"count\").desc()))\n",
    "\n",
    "    # Selecionar as top 10 palavras mais frequentes\n",
    "    top_10_words = word_counts.limit(10)\n",
    "\n",
    "    return top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47028d59-3731-4dfb-9ae8-9b20ec6b2908",
   "metadata": {},
   "source": [
    "#### Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706f8a75-2d28-4454-8ae8-1800a056f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    |12462|\n",
      "|   i| 8958|\n",
      "|  to| 7291|\n",
      "| the| 5329|\n",
      "|   a| 3804|\n",
      "|  my| 3800|\n",
      "| and| 3147|\n",
      "|  is| 2848|\n",
      "|  in| 2603|\n",
      "|  it| 2347|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Monday'\n",
    "top_10_words_monday = get_top_words_by_day(df, \"Monday\")\n",
    "top_10_words_monday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7462381-3dd6-47e8-9d02-e2f55a970f40",
   "metadata": {},
   "source": [
    "#### Tuesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41254472-4308-43ae-82cc-02776a00e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    | 7706|\n",
      "|   i| 5272|\n",
      "|  to| 4237|\n",
      "| the| 3492|\n",
      "|   a| 2435|\n",
      "|  my| 2262|\n",
      "| and| 1936|\n",
      "|  is| 1924|\n",
      "|  in| 1695|\n",
      "|  it| 1523|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Tuesday'\n",
    "top_10_words_tuesday = get_top_words_by_day(df, \"Tuesday\")\n",
    "\n",
    "top_10_words_tuesday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3ce61-fd54-4293-80c7-b805cade7e92",
   "metadata": {},
   "source": [
    "#### Wednesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a19d9f84-6874-4170-8bc6-1ee6c1de24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    | 1296|\n",
      "|   i| 1008|\n",
      "|  to|  707|\n",
      "| the|  538|\n",
      "|  my|  413|\n",
      "|   a|  371|\n",
      "| and|  305|\n",
      "|  is|  303|\n",
      "|  in|  253|\n",
      "|  im|  229|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Wednesday'\n",
    "top_10_words_wednesday = get_top_words_by_day(df, \"Wednesday\")\n",
    "\n",
    "top_10_words_wednesday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150ac97-b64b-415a-bac9-a56ade9b075f",
   "metadata": {},
   "source": [
    "#### Thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb9faa92-909a-478c-b874-b3a8bb39c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    | 5191|\n",
      "|   i| 3949|\n",
      "|  to| 2960|\n",
      "| the| 2238|\n",
      "|  my| 1673|\n",
      "|   a| 1668|\n",
      "| and| 1246|\n",
      "|  is| 1186|\n",
      "|  it| 1086|\n",
      "|  in| 1040|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Thursday'\n",
    "top_10_words_thursday = get_top_words_by_day(df, \"Thursday\")\n",
    "\n",
    "top_10_words_thursday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121cb7fa-4724-4337-ac68-9f518e2c585c",
   "metadata": {},
   "source": [
    "#### Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fd82406-9005-4c85-9646-ad7a1158ba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    | 3115|\n",
      "|   i| 2577|\n",
      "|  to| 1736|\n",
      "| the| 1305|\n",
      "|  my| 1009|\n",
      "|   a|  993|\n",
      "| and|  822|\n",
      "|  is|  697|\n",
      "|  im|  643|\n",
      "|  it|  640|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Friday'\n",
    "top_10_words_friday = get_top_words_by_day(df, \"Friday\")\n",
    "\n",
    "top_10_words_friday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f8703-f2ed-45d5-873d-f770fd6a7468",
   "metadata": {},
   "source": [
    "#### Saturday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c39525a-8e6d-41a5-ba5d-572e5d0f951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    |20566|\n",
      "|   i|16588|\n",
      "|  to|11008|\n",
      "| the| 8932|\n",
      "|   a| 6570|\n",
      "|  my| 6542|\n",
      "| and| 5255|\n",
      "|  is| 4605|\n",
      "|  in| 4091|\n",
      "|  it| 4042|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Saturday'\n",
    "top_10_words_saturday = get_top_words_by_day(df, \"Saturday\")\n",
    "\n",
    "top_10_words_saturday.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69dba0-4b1b-430b-87e7-647a6b81e060",
   "metadata": {},
   "source": [
    "#### Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09394e56-ec98-4417-a26c-937139a12310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|    |32293|\n",
      "|   i|24712|\n",
      "|  to|18280|\n",
      "| the|14089|\n",
      "|  my|10193|\n",
      "|   a|10012|\n",
      "| and| 8546|\n",
      "|  is| 7289|\n",
      "|  it| 6313|\n",
      "|  in| 6220|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usar a função para obter as palavras mais frequentes para 'Sunday'\n",
    "top_10_words_sunday = get_top_words_by_day(df, \"Sunday\")\n",
    "\n",
    "top_10_words_sunday.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
